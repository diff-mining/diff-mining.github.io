<!DOCTYPE html>
<html>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
<link rel="stylesheet" href="styles.css">

<head>
<title>Diff-Mining</title>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
   tex2jax: {
     inlineMath: [ ['$','$'], ["\\(","\\)"] ],
     processEscapes: true
   }
 });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
<link rel="icon" type="image/png" href="diffmining.png">
</head>

<body>

<h1>Diffusion&nbspModels&nbspas Data&nbspMining&nbspTools</h1>
<center>
  <div class="authors">
    <a href="https://ysig.github.io">Ioannis&nbspSiglidis</a><sup>1</sup>, <a href="https://holynski.org/">Aleksander&nbspHo≈Çy≈Ñski</a><sup>2</sup>,
    <a href="https://people.eecs.berkeley.edu/~efros/">Alexei&nbspA.&nbspEfros</a><sup>2</sup>, <br/>
    <a href="https://imagine.enpc.fr/~aubrym/">Mathieu&nbspAubry</a><sup>1</sup>,
    <a href="https://people.eecs.berkeley.edu/~shiry/">Shiry&nbspGinosar</a><sup>2</sup>
  </div>
  </div>
</center>

<div class="unis">
<center>
<sup>1</sup>LIGM,&nbspEcole&nbspdes&nbspPonts,&nbspUniv&nbspGustave&nbspEiffel,&nbspCNRS
<sup>2</sup>University&nbspof&nbspCalifornia,&nbspBerkeley
</center>
</div>

<div class="conf">
<center>
ECCV 2024
</center>
</div>


<div class="publication-links">
  <span class="link-block">
    <a href="arxiv.pdf" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fa-regular fa-file-lines" style="margin-right: 0.5rem;"></i> Pdf
      </span>
    </a>
  </span>

  <span class="link-block">
    <a href="https://arxiv.org/abs/2408.02752" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="ai ai-arxiv"></i> Arxiv
      </span>
    </a>
  </span>
  <span class="link-block">
    <a href="https://github.com/ysig/diff-mining" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fa-brands fa-github" style="margin-right: 0.5rem;"></i> Code
      </span>
    </a>
  </span>
  <span class="link-block">
    <a href="diffmining.tex" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
        <i class="fa-solid fa-star" style="margin-right: 0.5rem;"></i> bibtex
      </span>
    </a>
  </span>
  <span class="link-block">
    <a href="suppmat.html" class="external-link button is-normal is-rounded is-dark">
      <span class="icon">
          üöòüë©üñºÔ∏è
      </span>
    </a>
  </span>
</div>

<div class="image-container">
  <img src="media/Teaser.png" alt="Given a set of labelled data, we devise a method that ranks the most typical patches of these data and clusters them, leading in informative visual summaries." style="margin-top: 1em;">
</div>

<h2>Abstract</h2>
<div class="text">
This paper demonstrates how to use generative models trained for image synthesis as tools for visual data mining. Our insight is that since contemporary generative models learn an accurate representation of their training data, we can use them to summarize the data by mining for visual patterns. Concretely, we show that after finetuning conditional diffusion models to synthesize images from a specific dataset, we can use these models to define a typicality measure on that dataset. This measure assesses how typical visual elements are for different data labels, such as geographic location, time stamps, semantic labels, or even the presence of a disease. This analysis-by-synthesis approach to data mining has two key advantages. First, it scales much better than traditional correspondence-based approaches since it does not require explicitly comparing all pairs of visual elements. Second, while most previous works on visual data mining focus on a single dataset, our approach works on diverse datasets in terms of content and scale, including a historical car dataset, a historical face dataset, a large worldwide street-view dataset, and an even larger scene dataset. Furthermore, our approach allows for translating visual elements across class labels and analyzing consistent changes.
</div>

<h2>Extracted Visual Elements</h2>

<div id="carouselExampleDark" class="carousel carousel-dark slide" style="margin-bottom: -4em;">
  <div class="carousel-indicators" style="bottom: 3em">
    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="1" aria-label="Slide 2"></button>
    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="2" aria-label="Slide 3"></button>
    <button type="button" data-bs-target="#carouselExampleDark" data-bs-slide-to="3" aria-label="Slide 4"></button>
  </div>
  <div class="carousel-inner">
    <div class="carousel-item active" data-bs-interval="10000">
      <img src="visual-elements/g3.png" class="d-block w-100" alt="">
      <div class="carousel-caption d-none d-md-block" style="padding: 10px; bottom: 0; position: absolute; left: 0; right: 0; top: auto;">
        <p style="margin-top: 20px;"><a href="https://arxiv.org/abs/2211.15521" style="color: black;">G^3 (Luo et al. 2022)</a></p>
      </div>
    </div>
    <div class="carousel-item" data-bs-interval="10000">
      <img src="visual-elements/places.png" class="d-block w-100" alt="">
      <div class="carousel-caption d-none d-md-block" style="padding: 10px; bottom: 0; position: absolute; left: 0; right: 0; top: auto;">
        <p style="margin-top: 20px;"><a href="http://places2.csail.mit.edu/index.html" style="color: black;">Places (Zhou et al. 2017)</a></p>
      </div>
    </div>
    <div class="carousel-item" data-bs-interval="2000">
      <img src="visual-elements/ftt.png" class="d-block w-100" alt="">
      <div class="carousel-caption d-none d-md-block" style="padding: 10px; bottom: 0; position: absolute; left: 0; right: 0; top: auto;">
        <p style="margin-top: 20px;"><a href="https://facesthroughtime.github.io/" style="color: black;">Faces Through Time (Chen et al. 2023)</a></p>
      </div>
    </div>
    <div class="carousel-item">
      <img src="visual-elements/cardb.png" class="d-block w-100" alt="">
      <div class="carousel-caption d-none d-md-block" style="padding: 10px; bottom: 0; position: absolute; left: 0; right: 0; top: auto;">
        <p style="margin-top: 20px;"><a href="https://pages.cs.wisc.edu/~yongjaelee/projects/style_iccv2013.pdf" style="color: black;">CarDB (Lee et al. 2013)</a></p>
      </div>
    </div>
  </div>
  <button class="carousel-control-prev" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="prev">
    <span class="carousel-control-prev-icon" aria-hidden="true" style="color: white;"></span>
    <span class="visually-hidden">Previous</span>
  </button>
  <button class="carousel-control-next" type="button" data-bs-target="#carouselExampleDark" data-bs-slide="next">
    <span class="carousel-control-next-icon" aria-hidden="true" style="color: white;"></span>
    <span class="visually-hidden">Next</span>
  </button>
</div>

<h2>Approach</h2>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
Our approach takes as input a dataset with image-level tags, such as time, geography, or scene labels and produces a visual summary of the elements typical to the different tags, such as the common elements that enable us to determine the location of a streetview panorama. To arrive at this summary, we first finetune a conditional diffusion model on the target dataset. We then use the finetuned model to define a pixel-wise typicality measure by assessing the degree to which the label conditioning impacts the model's reconstruction of an image. We mine visual elements by aggregating typicality on patches, selecting the most typical ones, and clustering them using features extracted from the finetuned model. 
</div>

<div id="carousel2" class="carousel carousel-dark slide" style="margin-bottom: 5%;">
  <div class="carousel-indicators" style="top: 95%;">
    <button type="button" data-bs-target="#carousel2" data-bs-slide-to="0" class="active" aria-current="true" aria-label="Slide 1"></button>
    <button type="button" data-bs-target="#carousel2" data-bs-slide-to="1" aria-label="Slide 2"></button>
  </div>
  <div class="carousel-inner">
    <div class="carousel-item active" data-bs-interval="2000">
      <img src="approach/ranking.png" class="d-block w-100" alt="Patches from three datasets of faces, cars and geo ranked according to random, typicality and negative typicality.">
      <div class="carousel-caption d-none d-md-block" style="background-color: rgba(255,255,255,0.8); color: black; padding: 10px; bottom: 0;">
        <p><b>Typical elements are informative of the conditioning label.</b> We visualize the top-6 patches ranked according to typicality ($ \mathbf{T} $) with respect to the conditioning class label, negative typicality ($ -\mathbf{T} $), and randomly (Rand.). The two rows correspond to different classes from each of the four datasets.
        </p>
      </div>
    </div>
    <div class="carousel-item" data-bs-interval="10000">
      <img src="approach/finetuning.png" alt="Typicality visualized before and after finetuning across three datasets of faces cars and geo." class="d-block w-100">
      <div class="carousel-caption d-none d-md-block" style="background-color: rgba(255,255,255,0.8); color: black; padding: 10px; bottom: 0;">
        <p><b>Effect of finetuning.</b> For the same USA image (top), finetuning changes the spatial allocation of typicality before (middle) and after (bottom) finetuning <b>(a)</b>. This results in different typical clusters (USA), which, after finetuning (bottom), select for more typical elements like mailboxes <b>(b)</b>. Translation from France (top) to Thailand without finetuning (middle) suffers from data biases in the base model turning the road into a river and erasing utility poles. After finetuning on the G^3 dataset (bottom), the translated image is more consistent with the original <b>(c)</b>.
      </p>
      </div>
    </div>
  </div>
  <button class="carousel-control-prev" type="button" data-bs-target="#carousel2" data-bs-slide="prev">
    <span class="carousel-control-prev-icon" aria-hidden="true"></span>
    <span class="visually-hidden">Previous</span>
  </button>
  <button class="carousel-control-next" type="button" data-bs-target="#carousel2" data-bs-slide="next">
    <span class="carousel-control-next-icon" aria-hidden="true"></span>
    <span class="visually-hidden">Next</span>
  </button>
</div>

<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
<h3>1. Finetuning üìâ</h3>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
Given a label $ y $, we finetune a standard conditional latent diffusion model with a loss $ L_{t}\left(x, \epsilon, c(y)\right) $ and <a href="https://diffusionfeatures.github.io/">c.f.g.</a>, where $ c(y) $ is a prompt of the form $ c(y) = \text{"An image of {y}"} $.
</div>

<h3>2. Ranking üõï</h3>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
Inspired from <a href="https://diffusion-classifier.github.io/">Li et al. 2021</a>, we define a patch based ranking measure of typicality $\mathbf{T}$, given a conditioning label $ c $: $ \mathbf{T} (x|c) = \mathbb{E}_{\epsilon,t}[L_t(x, \epsilon, \varnothing) - L_t(x, \epsilon, c)]. $</td>
</div>

<h3>3. Clustering üß´</h3>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
After extracting the most typical patches from each image we cluster them using <a href="https://diffusionfeatures.github.io/">DIFT-161</a> features, and rank clusters according to their median typicality.
</div>

<h2>Applications</h2>

<h3>1. Summaries of variations. üóÉÔ∏è</h3>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
Having a diffusion model finetuned on a dataset of interest enables further applications that were not possible with previous visual mining approaches. One new application is the summary of variation of typical visual elements across different classes. As a case study, we use the G^3 dataset to discover and summarize how co-typical elements, such as windows, roofs, or license plates, vary across locations. Using <a href="https://pnp-diffusion.github.io/">Plug and Play</a> and our finetuned diffusion we create a "parallel dataset", by translating all the images in our mining dataset to all locations. Defining a co-typicality measure, allows us to mine the most typical transformations of visual elements, which we can then cluster by joint-clustering their concatenated features.
</div>

<figure>
  <div class="image-container">
    <img src="applications/variation.png" alt="Clustering typical translations of elements across countries">
  </div>
  <figcaption>
    <b>Clustering typical translations of elements across countries.</b> Ranking translated visual elements according to $\mathbf{T}$ and clustering the translated sequences results in groups of elements with similar variations. We show elements from 6 selected clusters out of 32. The source image for each sequence is highlighted in <span style="color: red;">red</span>.
  </figcaption>
</figure>

<h3 style="margin-top: 2em; margin-bottom: 1em;">2. X-ray localization. ü©ª</h3>
<div class="text" style="margin-top: 0em; margin-bottom: 2em;">
We test the localization property of typicality by finetuning Stable Diffusion on the ChestX-ray8 dataset, containing X-rays of patients who may suffer from a combination of various thorax diseases. Finetuning clearly improves the localization, which we quantify by computing the area under the precision recall-curve (AUC-PR) associated with ground truth ROIs. We see consistent improvement of this measure when finetuning the network (from 3.2% to 9.6%), ranging from +3.5% for Pneumonothorax (from 3% to 6%) to +14.6% for Mass (from 2% to 16.6%), which are respectively the least and most localized diseases. Similar to our other experiments, finetuning uses only image labels without localization supervision.
</div>

<figure>
  <div class="image-container">
    <img src="applications/xray.png" alt="Visualization of typicality on frontal view X-ray showing improve localization after finetuning">
  </div>
  <figcaption>
    <b>Localizing abnormal areas in medical images.</b> We visualize typicality when finetuning our model on the CXR8 dataset of thorax diseases. After fine-tuning (ft.), we can see a clear focus of the typicality score on expert annotated areas (<span style="color: red;">red</span> boxes) for each disease, while initial predictions from the pretrained Stable Diffusion V1.5 model (pt.) are mostly noise. Images are ordered by AUC-PR after finetuning. With $\uparrow$ we delimitate performance before and after finetuning, in the last row.
  </figcaption>
</figure>

<h2 style="margin-top: 2em;">Cite us</h2>
<pre><code class="language-bibtex">
  @article{diff-mining,
    title = {Diffusion Models as Data Mining Tools},
    author = {Siglidis, Ioannis and Holynski, Aleksander and Efros, A. Alexei and Aubry, Mathieu and Ginosar, Shiry},
    journal = {ECCV},
    year = {2024},
  }</code><button class="copy-code-button"><i class="fa-regular fa-clone"></i></button>
</pre>

<h2 style="margin-top: 2em;">Acknowledgments</h2>
<p>
<div class="text">
This work was partially supported by the European Research Council (ERC project DISCOVER, number 101076028) and leveraged the HPC resources of IDRIS under the allocation AD011012905R1, AD0110129052 made by GENCI. It was also partially supported by ONR MURI. We thank Grace Luo for data, code, and discussion; Loic Landreu and David Picard for insights on geographical representations and diffusion; Carl Doersch, for project advice and implementation insights; Sophia Koepke for feedback on our manuscript. 
</div>
</p>

<!-- <h4>Font stolen from Gwern.</h4> -->
<script>
  // Add click event listener to each copy code button
  document.querySelectorAll(".copy-code-button").forEach(function(button) {
    button.addEventListener("click", function() {
      // Get the code element
      var codeElement = this.parentElement.querySelector("code");
 
      // Create a temporary textarea to copy the code
      var textarea = document.createElement("textarea");
      textarea.value = codeElement.innerText;
      document.body.appendChild(textarea);
 
      // Select and copy the code
      textarea.select();
      document.execCommand("copy");
 
      // Remove the temporary textarea
      document.body.removeChild(textarea);
 
      // Change the button text to "Copied!" for a short duration
      var originalText = this.innerText;
      this.innerText = "Copied!";
      setTimeout(function() {
        button.innerHTML = "<i class=\"fa-regular fa-clone\"></i>";
      }, 1500);
    });
  });
</script>
</body>
</html>
